流程：
    数据获取与准备(数据的清理、缩放)
    选择和训练模型(模型训练、评分、更换，交叉验证)
        训练集上的分数仍然远低于验证集，这意味着该模型仍然对训练集过度拟合。过度拟合的可能解决方案包括简化模型、约束模型（即使其正规化），或是获得更多的训练数据。尝试一遍各种机器学习算法的其他模型（几种具有不同内核的支持向量机，比如神经网络模型等），但是记住——别花太多时间去调整超参数。我们的目的是筛选出几个（2～5个）有效的模型。
    调参(GridSearchCV与RandomizedSearchCV)。删除/添加特征值看看效果
    预启用:现在进入项目预启动阶段：你将要展示你的解决方案（强调学习了什么，什么有用，什么没有用，基于什么假设，以及系统的限制有哪些），记录所有事情，通过清晰的可视化和易于记忆的陈述方式，制作漂亮的演示文稿（例如，“收入中位数是预测房价的首要指标”）
    监控、维护系统(在线系统学习)


一、sklearn主要设计原则：
    1.一致性
    2.估算器（fit()）
    3.转换器（transform() / fit_transform()）
    4.预测器（predict()-score()）
    5.检查
    6.防止类扩散
    7.转换
    8.合理的默认值

二、同比例缩放属性
    1.最小-最大缩放(归一化)：将值重新缩放使其最终范围归于0到1之间。实现方法是将值减去最小值并除以最大值和最小值的差。对此，Scikit-Learn提供了一个名为MinMaxScaler的转换器。如果出于某种原因，你希望范围不是0～1，你可以通过调整超参数feature_range进行更改。
    2.标准化：首先减去平均值（所以标准化值的均值总是零），然后除以方差，从而使得结果的分布具备单位方差。不同于最小-最大缩放的是，标准化不将值绑定到特定范围，对某些算法而言，这可能是个问题。但是标准化的方法受异常值的影响更小。例如，假设某个地区的平均收入等于100（错误数据）。最小-最大缩放会将所有其他值从0～15降到0～0.15，而标准化则不会受到很大影响。Scikit-Learn提供了一个标准化的转换器StandadScaler。

三、模型对训练数据拟合不足
    通常意味着这些特征可能无法提供足够的信息来做出更好的预测，或者是模型本身不够强大。
    想要修正拟合不足，可以通过选择更强大的模型，或是为算法训练提供更好的特征，又或者是减少对模型的限制等方法。
    （如用DecisionTreeRegressor替代LinearRegression，用RandomForestRegressor替代DecisionTreeRegressor）
