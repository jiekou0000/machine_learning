正则化：
    目的：降低模型复杂度，增加模型泛化能力，防止过拟合。 a越大越泛化?
    常用方式：在目标函数后面添加一个系数的“惩罚项”，为了防止系数过大从而让模型变得复杂(常用L2)
        L1正则化：让原目标函数加上所有特征系数绝对值的和来实现正则化。系数更新会减去一个常数，会让特征变得稀疏(去除相关特征)。更适用于特征选择  Lasso
        L2正则化：让原目标函数加上所有特征系数的平方和来实现正则化。系数更新会进行一个比例的缩放，让模型变得更简单(曲线平缓连续)。更适用于防止模型过拟合  Ridge

坐标下降法：
    坐标下降法基于的思想是多变量函数F(x)可以通过每次沿一个方向优化来获取最小值


训练模型的方法：
    1.通过“闭式”方程
    2.梯度下降(GD)


